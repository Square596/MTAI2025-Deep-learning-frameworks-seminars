{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuDotMn6HTUQ"
      },
      "source": [
        "# TensorRT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30JaAa7DJ3_D"
      },
      "source": [
        "## Установка зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjbB2JHo6-3A",
        "outputId": "c48cef8e-dd2f-4c8f-de52-2bb9cfde96ca"
      },
      "outputs": [],
      "source": [
        "# !pip3 install torch-tensorrt==2.8.0 -f https://github.com/pytorch/TensorRT/releases/expanded_assets/2.8.0\n",
        "# !pip install -U \"nvidia-modelopt[all]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFFx7LYUG6Qo"
      },
      "source": [
        "## Датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "df: /home/ubuntu/.triton/autotune: No such file or directory\n",
            "/home/ubuntu/miniconda3/envs/sem10/compiler_compat/ld: cannot find -laio: No such file or directory\n",
            "collect2: error: ld returned 1 exit status\n",
            "/home/ubuntu/miniconda3/envs/sem10/compiler_compat/ld: cannot find -laio: No such file or directory\n",
            "collect2: error: ld returned 1 exit status\n",
            "TensorRT-LLM is not installed. Please install TensorRT-LLM or set TRTLLM_PLUGINS_PATH to the directory containing libnvinfer_plugin_tensorrt_llm.so to use converters for torch.distributed ops\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.utils.cpp_extension\n",
        "from torch import nn\n",
        "\n",
        "import torch_tensorrt\n",
        "import modelopt.torch.quantization as mtq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oOW61jT5KKix"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "testing_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "testing_dataloader = torch.utils.data.DataLoader(\n",
        "    testing_dataset, batch_size=1, shuffle=False, num_workers=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQg7Q5QA1p_A"
      },
      "source": [
        "### Функция калибровки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YbwkIeziKqDT"
      },
      "outputs": [],
      "source": [
        "def forward_loop(model):\n",
        "    for img, _ in testing_dataloader:\n",
        "        img = img.to(device)\n",
        "        model(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_EX4cdH12dC"
      },
      "source": [
        "### Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t7upjKOB13ti"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet18().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3kBiS_K1yFY"
      },
      "source": [
        "### Квантизация при помощи TensorRT Model Optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8TAxxJDKrXC",
        "outputId": "75ab2cfa-d9d5-45b6-cfaa-fdeb8b30318d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 107 quantizers\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "config = mtq.INT8_DEFAULT_CFG\n",
        "\n",
        "quantized_model = mtq.quantize(model, config, forward_loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qF0Nl9Cc4IM2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.input_quantizer                                                            TensorQuantizer(8 bit fake per-tensor amax=2.7537 calibrator=MaxCalibrator quant)\n",
            "conv1.output_quantizer                                                           TensorQuantizer(disabled)\n",
            "conv1.weight_quantizer                                                           TensorQuantizer(8 bit fake axis=0 amax=[0.0550, 0.0980](64) calibrator=MaxCalibrator quant)\n",
            "bn1.input_quantizer                                                              TensorQuantizer(disabled)\n",
            "bn1.output_quantizer                                                             TensorQuantizer(disabled)\n",
            "maxpool.input_quantizer                                                          TensorQuantizer(8 bit fake per-tensor amax=2.3091 calibrator=MaxCalibrator quant)\n",
            "maxpool.output_quantizer                                                         TensorQuantizer(disabled)\n",
            "layer1.0.conv1.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=2.3091 calibrator=MaxCalibrator quant)\n",
            "layer1.0.conv1.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer1.0.conv1.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.1538, 0.2539](64) calibrator=MaxCalibrator quant)\n",
            "layer1.0.bn1.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer1.0.bn1.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer1.0.conv2.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=3.5495 calibrator=MaxCalibrator quant)\n",
            "layer1.0.conv2.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer1.0.conv2.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.1385, 0.2458](64) calibrator=MaxCalibrator quant)\n",
            "layer1.0.bn2.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer1.0.bn2.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer1.1.conv1.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=4.1930 calibrator=MaxCalibrator quant)\n",
            "layer1.1.conv1.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer1.1.conv1.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.1563, 0.2484](64) calibrator=MaxCalibrator quant)\n",
            "layer1.1.bn1.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer1.1.bn1.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer1.1.conv2.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=5.3463 calibrator=MaxCalibrator quant)\n",
            "layer1.1.conv2.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer1.1.conv2.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.1421, 0.2532](64) calibrator=MaxCalibrator quant)\n",
            "layer1.1.bn2.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer1.1.bn2.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer2.0.conv1.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=7.4700 calibrator=MaxCalibrator quant)\n",
            "layer2.0.conv1.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer2.0.conv1.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.1054, 0.2009](128) calibrator=MaxCalibrator quant)\n",
            "layer2.0.bn1.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer2.0.bn1.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer2.0.conv2.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=5.7484 calibrator=MaxCalibrator quant)\n",
            "layer2.0.conv2.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer2.0.conv2.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.1193, 0.1795](128) calibrator=MaxCalibrator quant)\n",
            "layer2.0.bn2.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer2.0.bn2.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer2.0.downsample.0.input_quantizer                                            TensorQuantizer(8 bit fake per-tensor amax=7.4700 calibrator=MaxCalibrator quant)\n",
            "layer2.0.downsample.0.output_quantizer                                           TensorQuantizer(disabled)\n",
            "layer2.0.downsample.0.weight_quantizer                                           TensorQuantizer(8 bit fake axis=0 amax=[0.2050, 0.4572](128) calibrator=MaxCalibrator quant)\n",
            "layer2.0.downsample.1.input_quantizer                                            TensorQuantizer(disabled)\n",
            "layer2.0.downsample.1.output_quantizer                                           TensorQuantizer(disabled)\n",
            "layer2.1.conv1.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=7.1697 calibrator=MaxCalibrator quant)\n",
            "layer2.1.conv1.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer2.1.conv1.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.1206, 0.1904](128) calibrator=MaxCalibrator quant)\n",
            "layer2.1.bn1.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer2.1.bn1.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer2.1.conv2.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=7.0823 calibrator=MaxCalibrator quant)\n",
            "layer2.1.conv2.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer2.1.conv2.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.1174, 0.2014](128) calibrator=MaxCalibrator quant)\n",
            "layer2.1.bn2.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer2.1.bn2.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer3.0.conv1.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=8.2706 calibrator=MaxCalibrator quant)\n",
            "layer3.0.conv1.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer3.0.conv1.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.0849, 0.1416](256) calibrator=MaxCalibrator quant)\n",
            "layer3.0.bn1.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer3.0.bn1.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer3.0.conv2.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=7.7618 calibrator=MaxCalibrator quant)\n",
            "layer3.0.conv2.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer3.0.conv2.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.0885, 0.1526](256) calibrator=MaxCalibrator quant)\n",
            "layer3.0.bn2.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer3.0.bn2.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer3.0.downsample.0.input_quantizer                                            TensorQuantizer(8 bit fake per-tensor amax=8.2706 calibrator=MaxCalibrator quant)\n",
            "layer3.0.downsample.0.output_quantizer                                           TensorQuantizer(disabled)\n",
            "layer3.0.downsample.0.weight_quantizer                                           TensorQuantizer(8 bit fake axis=0 amax=[0.1617, 0.4009](256) calibrator=MaxCalibrator quant)\n",
            "layer3.0.downsample.1.input_quantizer                                            TensorQuantizer(disabled)\n",
            "layer3.0.downsample.1.output_quantizer                                           TensorQuantizer(disabled)\n",
            "layer3.1.conv1.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=7.7059 calibrator=MaxCalibrator quant)\n",
            "layer3.1.conv1.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer3.1.conv1.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.0861, 0.1517](256) calibrator=MaxCalibrator quant)\n",
            "layer3.1.bn1.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer3.1.bn1.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer3.1.conv2.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=4.8635 calibrator=MaxCalibrator quant)\n",
            "layer3.1.conv2.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer3.1.conv2.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.0911, 0.1428](256) calibrator=MaxCalibrator quant)\n",
            "layer3.1.bn2.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer3.1.bn2.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer4.0.conv1.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=7.8910 calibrator=MaxCalibrator quant)\n",
            "layer4.0.conv1.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer4.0.conv1.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.0624, 0.1034](512) calibrator=MaxCalibrator quant)\n",
            "layer4.0.bn1.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer4.0.bn1.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer4.0.conv2.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=3.0249 calibrator=MaxCalibrator quant)\n",
            "layer4.0.conv2.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer4.0.conv2.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.0663, 0.1127](512) calibrator=MaxCalibrator quant)\n",
            "layer4.0.bn2.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer4.0.bn2.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer4.0.downsample.0.input_quantizer                                            TensorQuantizer(8 bit fake per-tensor amax=7.8910 calibrator=MaxCalibrator quant)\n",
            "layer4.0.downsample.0.output_quantizer                                           TensorQuantizer(disabled)\n",
            "layer4.0.downsample.0.weight_quantizer                                           TensorQuantizer(8 bit fake axis=0 amax=[0.1303, 0.2968](512) calibrator=MaxCalibrator quant)\n",
            "layer4.0.downsample.1.input_quantizer                                            TensorQuantizer(disabled)\n",
            "layer4.0.downsample.1.output_quantizer                                           TensorQuantizer(disabled)\n",
            "layer4.1.conv1.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=4.4382 calibrator=MaxCalibrator quant)\n",
            "layer4.1.conv1.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer4.1.conv1.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.0650, 0.1061](512) calibrator=MaxCalibrator quant)\n",
            "layer4.1.bn1.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer4.1.bn1.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "layer4.1.conv2.input_quantizer                                                   TensorQuantizer(8 bit fake per-tensor amax=1.5590 calibrator=MaxCalibrator quant)\n",
            "layer4.1.conv2.output_quantizer                                                  TensorQuantizer(disabled)\n",
            "layer4.1.conv2.weight_quantizer                                                  TensorQuantizer(8 bit fake axis=0 amax=[0.0670, 0.1091](512) calibrator=MaxCalibrator quant)\n",
            "layer4.1.bn2.input_quantizer                                                     TensorQuantizer(disabled)\n",
            "layer4.1.bn2.output_quantizer                                                    TensorQuantizer(disabled)\n",
            "avgpool.input_quantizer                                                          TensorQuantizer(8 bit fake per-tensor amax=4.4898 calibrator=MaxCalibrator quant)\n",
            "avgpool.output_quantizer                                                         TensorQuantizer(disabled)\n",
            "fc.input_quantizer                                                               TensorQuantizer(8 bit fake per-tensor amax=4.4898 calibrator=MaxCalibrator quant)\n",
            "fc.output_quantizer                                                              TensorQuantizer(disabled)\n",
            "fc.weight_quantizer                                                              TensorQuantizer(8 bit fake axis=0 amax=[0.0437, 0.0442](1000) calibrator=MaxCalibrator quant)\n",
            "107 TensorQuantizers found in model\n"
          ]
        }
      ],
      "source": [
        "mtq.print_quant_summary(quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FCzs4kJG6pH"
      },
      "source": [
        "# Задание на семинар\n",
        "\n",
        "Нужно квантизировать при помощи TensorRT любую модель из torchvision или timm (hugging-face) до int8 и до float16. Затем нужно проверить скорость работы получившихся вариаций модели (float32 - исходная, float16 и int8) и их размер. Результаты привести в блокноте.\n",
        "\n",
        "## Решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/miniconda3/envs/sem10/compiler_compat/ld: cannot find -laio: No such file or directory\n",
            "collect2: error: ld returned 1 exit status\n",
            "/home/ubuntu/miniconda3/envs/sem10/compiler_compat/ld: cannot find -laio: No such file or directory\n",
            "collect2: error: ld returned 1 exit status\n",
            "TensorRT-LLM is not installed. Please install TensorRT-LLM or set TRTLLM_PLUGINS_PATH to the directory containing libnvinfer_plugin_tensorrt_llm.so to use converters for torch.distributed ops\n"
          ]
        }
      ],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch_tensorrt\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchao.utils import benchmark_model\n",
        "import os\n",
        "\n",
        "from typing import Tuple\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def benchmark_speed(model_orig: nn.Module,\n",
        "                    model_quant: nn.Module,\n",
        "                    example_inputs: torch.Tensor,\n",
        "                    num_runs: int = 100):\n",
        "    torch._dynamo.reset()\n",
        "    orig_time = benchmark_model(model_orig, num_runs, example_inputs)\n",
        "    quant_time = benchmark_model(model_quant, num_runs, example_inputs)\n",
        "\n",
        "    print(\"orig mean time: %0.3f ms\" % orig_time)\n",
        "    print(\"quant mean time: %0.3f ms\" % quant_time)\n",
        "    print(\"speedup: %0.1fx\" % (orig_time / quant_time))\n",
        "    torch._dynamo.reset()\n",
        "\n",
        "\n",
        "def benchmark_size(model_orig: nn.Module, model_quant: nn.Module):\n",
        "    \"\"\"\n",
        "    re-implemented function - i use modelopt and those models can't be pickled\n",
        "    so i calculate size another way\n",
        "    \"\"\"\n",
        "    def get_model_size_mb(model: nn.Module):\n",
        "        param_size = 0\n",
        "        buffer_size = 0\n",
        "\n",
        "        for param in model.parameters():\n",
        "            param_size += param.nelement() * param.element_size()\n",
        "\n",
        "        for buffer in model.buffers():\n",
        "            buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "        size_all_mb = (param_size + buffer_size) / 1024.0 / 1024.0\n",
        "        return size_all_mb\n",
        "\n",
        "    # Try to save original model normally\n",
        "    try:\n",
        "        torch.save(model_orig, \"/tmp/orig_model.pt\")\n",
        "        orig_model_size_mb = os.path.getsize(\"/tmp/orig_model.pt\") / 1024 / 1024\n",
        "        print(\"original model using save\")\n",
        "    except Exception:\n",
        "        # Fallback to parameter-based calculation\n",
        "        orig_model_size_mb = get_model_size_mb(model_orig)\n",
        "        print(\"original model using parameter-based calculation\")\n",
        "\n",
        "    try:\n",
        "        # Try saving state_dict instead of full model\n",
        "        torch.save(model_quant.state_dict(), \"/tmp/quant_model_state.pt\")\n",
        "        quant_model_size_mb = os.path.getsize(\"/tmp/quant_model_state.pt\") / 1024 / 1024\n",
        "        print(\"quant model using save\")\n",
        "    except Exception:\n",
        "        # Fallback to parameter-based calculation\n",
        "        quant_model_size_mb = get_model_size_mb(model_quant)\n",
        "        print(\"quant model using parameter-based calculation\")\n",
        "\n",
        "    print(\"quant model size: %.2f MB\" % quant_model_size_mb)\n",
        "    print(\"original model size: %.2f MB\" % orig_model_size_mb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = timm.create_model('vit_base_patch14_dinov2.lvd142m').cuda()\n",
        "model.eval()\n",
        ";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            transforms.Resize((518, 518))\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=1, shuffle=False, num_workers=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_loop(model):\n",
        "    for img, _ in dataloader:\n",
        "        img = img.to(device)\n",
        "        model(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 147 quantizers\n"
          ]
        }
      ],
      "source": [
        "import modelopt.torch.quantization as mtq\n",
        "\n",
        "original_model = deepcopy(model)\n",
        "fp8_model = mtq.quantize(model, mtq.FP8_DEFAULT_CFG, forward_loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 147 quantizers\n"
          ]
        }
      ],
      "source": [
        "original_model2 = deepcopy(original_model)\n",
        "int8_model = mtq.quantize(original_model, mtq.INT8_DEFAULT_CFG, forward_loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "BENCHMARKING SPEED\n",
            "==================================================\n",
            "\n",
            "1. Original model (float32) vs Float8:\n",
            "Loading extension modelopt_cuda_ext_fp8...\n",
            "Loaded extension modelopt_cuda_ext_fp8 in 0.0 seconds\n",
            "orig mean time: 12.764 ms\n",
            "quant mean time: 23.147 ms\n",
            "speedup: 0.6x\n",
            "\n",
            "2. Original model (float32) vs Int8:\n",
            "Loading extension modelopt_cuda_ext...\n",
            "Loaded extension modelopt_cuda_ext in 0.0 seconds\n",
            "orig mean time: 12.729 ms\n",
            "quant mean time: 19.448 ms\n",
            "speedup: 0.7x\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"BENCHMARKING SPEED\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "example_input = torch.rand(1, 3, 518, 518).cuda()\n",
        "\n",
        "print(\"\\n1. Original model (float32) vs Float8:\")\n",
        "benchmark_speed(original_model2, fp8_model, (example_input, ))\n",
        "\n",
        "print(\"\\n2. Original model (float32) vs Int8:\")\n",
        "benchmark_speed(original_model2, int8_model, (example_input, ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "BENCHMARKING SIZE\n",
            "==================================================\n",
            "\n",
            "1. Original model (float32) vs Float16:\n",
            "original model using save\n",
            "quant model using save\n",
            "quant model size: 330.38 MB\n",
            "original model size: 330.39 MB\n",
            "\n",
            "2. Original model (float32) vs Int8:\n",
            "original model using save\n",
            "quant model using save\n",
            "quant model size: 330.70 MB\n",
            "original model size: 330.39 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"BENCHMARKING SIZE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\n1. Original model (float32) vs Float16:\")\n",
        "benchmark_size(original_model2, fp8_model)\n",
        "\n",
        "print(\"\\n2. Original model (float32) vs Int8:\")\n",
        "benchmark_size(original_model2, int8_model)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sem10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
